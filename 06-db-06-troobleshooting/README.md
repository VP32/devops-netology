# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB


**Ответ:**

- найти медленный запрос с помощью команды db.currentOp(), например с указанием минимальной продолжительности запроса:  `db.currentOp({"secs_running": {$gte: 5}})`, затем остановить запрос командой db.killOp() по id операции
- на стороне клиента можно использовать метод cursor.maxTimeMS() для установки таймаута запроса. Также нужно выяснить, что происходит с зависающим запросом с помощью метода .explan("executionStats")

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

**Ответ:**

Причина в росте количества одновременно истекающих значений, и Redis не справляется с их одновременным удалением, при этом блокирует запись. 
В Redis используются 2 способа очистки просроченных записей:
 - активный - по команде запроса записи, когда выясняется, что она просрочена
 - ленивый - запускается автоматически каждые 100 миллисекунд, переводя записи в состояние устаревшие, затем данные записи исключаются. 

Выбирается ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP записей, которое по умолчанию имеет значение 20, таким образом за раз можно пометить и очистить около 200 устаревших записей. Процесс проверки зацикливается, будут заметны задержки, а потом и вовсе не будут приниматься данные на запись, если появятся истекшие записи более 25% по отношению ко всем записям.

В этой ситуации лучше стараться не писать множество значений с одинаковым TTL одномоментно, чтобы снизить количество одновременно истекающих ключей.
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

**Ответ:**

Тут возможны варианты, что запрос оперирует миллионами записей, либо в рамках одной записи используются слишком большие BLOB-поля. Необходимо уточнить, в чем проблема, проанализировав проблемные запросы с помощью EXPLAIN. В первом варианте нужно увеличить настройку net_read_timeout с дефолтного значения до 60 секунд или более, во втором - увеличить настройку max-allowed-packet. По возможности нужно оптимизировать сами запросы, добавить недостающие индексы к таблицам. 

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

**Ответ:**

Проблема в нехватке оперативной памяти. Мы видим, что система с помощью Out-Of-Memory Killer останавливает процесс, потребляющий слишком много оперативной памяти, чтобы защитить ядро от падения. В нашем случае останавливается процесс СУБД. Нужно либо добавить оперативки, либо ограничить использование оперативки для Postgres. По возможности необходимо оптимизировать проблемные запросы в БД, добавить недостающие индексы к таблицам.
