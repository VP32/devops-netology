# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB


**Ответ:**

- найти медленный запрос с помощью команды db.currentOp(), например с указанием минимальной продолжительности запроса:  `db.currentOp({"secs_running": {$gte: 5}})`, затем остановить запрос командой db.killOp() по id операции
- на стороне клиента можно использовать метод cursor.maxTimeMS() для установки таймаута запроса. Также нужно выяснить, что происходит с зависающим запросом с помощью метода .explan("executionStats"), возможно сделать оптимизацию запроса и данных

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

**Ответ:**

Причина в росте количества одновременно истекающих значений, и Redis не справляется с их одновременным удалением, при этом блокирует запись. 
В Redis используются 2 способа очистки просроченных записей:
 - активный - по команде запроса записи, когда выясняется, что она просрочена
 - ленивый - запускается автоматически каждые 100 миллисекунд, переводя записи в состояние устаревшие, затем данные записи исключаются. 

Выбирается ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP записей, которое по умолчанию имеет значение 20, таким образом за раз можно пометить и очистить около 200 устаревших записей. Процесс проверки зацикливается, будут заметны задержки, а потом и вовсе не будут приниматься данные на запись, если появятся истекшие записи более 25% по отношению ко всем записям.

В этой ситуации лучше стараться не писать множество значений с одинаковым TTL одномоментно, чтобы снизить количество одновременно истекающих ключей.
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

**Ответ:**

Тут возможны варианты, что запрос оперирует миллионами записей, либо в рамках одной записи используются слишком большие BLOB-поля. Необходимо уточнить, в чем проблема, проанализировав проблемные запросы с помощью EXPLAIN. В первом варианте нужно увеличить настройку net_read_timeout с дефолтного значения до 60 секунд или более, во втором - увеличить настройку max-allowed-packet. По возможности нужно оптимизировать сами запросы, добавить недостающие индексы к таблицам. 

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

**Ответ:**

Проблема в нехватке оперативной памяти. Мы видим, что система с помощью Out-Of-Memory Killer останавливает процесс, потребляющий слишком много оперативной памяти, чтобы защитить ядро от падения. В нашем случае останавливается процесс СУБД. Нужно либо добавить оперативки, либо ограничить использование оперативки для Postgres. По возможности необходимо оптимизировать проблемные запросы в БД, добавить недостающие индексы к таблицам.

Для настройки работы с оперативной памятью из Postgres можно регулировать следующие параметры:


**max_connections** - Определяет максимальное число одновременных подключений к серверу БД. По умолчанию 100 подключений. Можно попробовать убавить его.

**shared_buffers** - Задаёт объём памяти, который будет использовать сервер баз данных для буферов в разделяемой памяти. По умолчанию установлено 128 мегабайт. На системах с RAM 1 Гб и выше рекомендуется использовать 25% от общего объема памяти. Если оперативки меньше, то нужно использовать меньший процент, чтобы оставить памяти для системы.

**wal_buffers** - Postgres сначала записывает записи в WAL (журнал предзаписи) в буферы, а затем эти буферы сбрасываются на диск. Размер буфера по умолчанию, равный -1, задаёт размер, равный 1/32 (около 3%) от shared_buffers, но не меньше чем 64 КБ и не больше чем размер одного сегмента WAL (обычно 16 МБ). Если у нас много одновременных подключений, то более высокое значение может повысить производительность. По документации рекомендуется использовать автонастройку со значением -1, однако можно попробовать скорректировать этот параметр.


**effective_cache_size** - Определяет представление планировщика об эффективном размере дискового кеша, доступном для одного запроса. Это представление влияет на оценку стоимости использования индекса; чем выше это значение, тем больше вероятность, что будет применяться сканирование по индексу, чем ниже, тем более вероятно, что будет выбрано последовательное сканирование.  Значение по умолчанию — 4 гигабайта.

 **temp_buffers** - Задаёт максимальный объём памяти, выделяемой для временных буферов в каждом сеансе. Эти существующие только в рамках сеанса буферы используются исключительно для работы с временными таблицами. Значение по умолчанию — 8 мегабайт. Сеанс выделяет временные буферы по мере необходимости до достижения предела, заданного параметром temp_buffers. 

**work_mem** - Задаёт базовый максимальный объём памяти, который будет использоваться во внутренних операциях при обработке запросов (например, для сортировки или хеш-таблиц), прежде чем будут задействованы временные файлы на диске. Значение по умолчанию — 4 мегабайта. Применяется для каждой операции сортировки или хеширования, при этом таких операций может быть несколько и одновременно в разных сеансах. Установка высокого значения может привести к высокому потреблению памяти.

**maintenance_work_mem** - это максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX и ALTER TABLE ADD FOREIGN KEY.  Значение по умолчанию — 64 мегабайта. Так как в один момент времени в сеансе может выполняться только одна такая операция и обычно они не запускаются параллельно, это значение вполне может быть гораздо больше work_mem. Увеличение этого значения может привести к ускорению операций очистки и восстановления БД из копии, но может приводить к высокому потреблению памяти.