# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

## Решение

<table>
<tbody>
<tr>
<th scope="row" valign="top">
 Краткое описание инцидента
</th>
<td>
В 22:52 (21.10.2018) по UTC на нескольких сервисах GitHub.com пострадали несколько сетевых разделов с последующим сбоем базы данных, что привело к отображению непоследовательной информации. 


Деградация сервиса продолжалась 24 часа и 11 минут.

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Предшествующие события
</th>
<td>

В 22:52 по UTC 21 октября 2018 проводились плановые замены отказавшего 100Гб оптического оборудования. Они привели к потере связи на 43 секунды между сетевым узлом US East Coast и основным ЦОД US East Coast.

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Причина инцидента 
</th>
<td>
    Потеря связи привела к рассогласованию кластеров MySQL.

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Воздействие
</th>
<td>

Несогласованность отображаемой информации, отображение устаревших данных.

Также была невозоможна обработка вебхуков и сборка публикация сайтов GitHub Pages. 


</td>
</tr>
<tr>
<th scope="row" valign="top">
 Обнаружение
</th>
<td>
    Обнаружили инцидент инженеры, обрабатывающие алерты от системы мониторинга. Далее предупреждение получил координатор инцидентов. Затем им к работе были привлечены разработчики из инженерной группы БД. 

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Реакция
</th>
<td>

 Деградация сервиса в течение 24 часа и 11 минут.
</td>
</tr>
<tr>
<th scope="row" valign="top">
 Восстановление
</th>
<td>
Восстановление было произведено путем восстановления файлов из бэкапов, повторной репликации БД, после чего вернулась стабильная топология обслуживания, и далее возобновлена обработка заданий в очереди.

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Таймлайн
</th>
<td>

21.10.2018, 22:52 UTC - потеря консенсуса между сереврами в дата хабах. После восстановления была попытка восстановления целостности кластера, восстановления консенсуса, но данные в БД различялись что привело к несогласованности в рамках кластера 

21.10.2018, 22:54 UTC -  системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем. К 23:02 инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии: не обнаружены серверы из US East Coast.

21.10.2018, 23:07 UTC - вручную заблокированы внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений. В 23:09 установлен жёлтый статус работоспособности сайта. Отправлен инцидент в систему управления инцидентами. В 23:11 координатор присоединился к работе и принял решение изменить статус инцидента на красный.

21.10.2018, 23:13 UTC - выявлены воздействия на множественные кластеры БД, к работе привлечены дополнительные инженеры, выполнены действия для сохранения пользовательских данных.

21.10.2018, 23:19 UTC - введена ручная деградация с целью обеспечения целостности данных. Остановлены вебхуки и сборка GitHub Pages.

22.10.2018, 00:05 UTC - разработан план устранения несогласованности данных. Обновлен статус, чтобы сообщить пользователям, что GitHub собираемся выполнить управляемую отработку отказа внутренней системы хранения данных.

22.10.2018, 00:41 UTC - запущен процесс резервного копирования для всех затронутых кластеров MySQL, инженеры отслеживали прогресс. Параллельно несколько групп инженеров изучали способы ускорения передачи и восстановления без дальнейшей деградации сайта или риска повреждения данных.

22.10.2018, 06:51 UTC - завершено восстановление из бэкапов ЦОД US East Coast, запущена репликация с серверов в West Coast. Была вычислена и обновлена оценка времени восстановления, обновлена страница состояния восстановления.

22.10.2018, 07:46 UTC - опубликовано официальное сообщение о ходе восстановления в блоге для пользователей.

22.10.2018, 11:12 UTC - Востановлены серверы в US East Coast, продолжается репликация, наблюдается повышенная нагрузка при реплицировании. 

22.10.2018, 13:15 UTC - пик нагрузки на GitHub.com. Обсуждение дальнейших действий в команде реагирования. Увеличивается отставание репликации до согласованного состояния.  Подготовка дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья, распределение потоков с учетом дополнительно развернутых реплик MySQL. Уменьшение средней нагрузки на реплики чтения ускорило догон репликации.

22.10.2018, 16:24 UTC - завершение репликации, переключение к штатной топологии. 

22.10.2018, 16:45 UTC - запуск работы вебхуков и сборок веб-страниц. На этапе восстановления не удалось сбалансировать возросшую нагрузку и в результате около 200000 полезных задач были отброшены ввиду превышения TTL. Остановка обработки и увеличение TTL для обработки вебхуков, чтобы успеть обработать все накопившиеся задания. 

22.10.2018, 23:03 UTC

Все незавершённые события вебхуков и сборки GitHub Pages обработаны,  целостность и правильная работа всех систем подтверждена. Статус сайта обновлён на зелёный.

</td>
</tr>
<tr>
<th scope="row" valign="top">
 Последующие действия 
</th>
<td>

В ходе анализа событий был принят ряд технических мер: 

- Отрегулировать конфигурацию Orchestrator, чтобы запретить перемещение первичных БД за границы региона;
- ускорить миграцию на новую систему отчётности по статусам, которая предоставит более развернутую информацию по инциденту, ранее были доступны только зелёный, жёлтый и красный статусы для всего сайта, это не даёт точной картины: что работает, а что нет. Новая система будет отображать различные компоненты платформы, чтобы был известен статус каждой службы;

- запустили общекорпоративную инженерную инициативу для поддержки обслуживания трафика GitHub из нескольких ЦОД по архитектуре active/active/active. Цель данного проекта — поддержка избыточности N+1 на уровне ЦОД, чтобы выдерживать отказ одного ЦОД без вмешательства со стороны
- начата истемная практика проверки сценариев сбоев, прежде чем они возникнут в реальности. Эта работа включает умышленное внесение неисправностей и применение инструментов хаос-инжиниринга.


</td>
</tr>
<tr>
</tbody>
</table>
